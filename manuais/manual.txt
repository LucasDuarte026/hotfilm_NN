Os algoritmos em python encontrados dentro de `hotfilm_NN` têm como possível o argumento
"?" para se obter informações de como indicar os parâmetros de entrada

Antes de tudo:
    1. Após ter instalado o virtual environment, vá para a pasta do projeto (será a mesma em que está este manual) e deixe como raiz no bash;
    2. execute o comando:
        $ source hotfilm_env/bin/activate
        obs: Caso queira sair do ambiente, execute:
            $ deactivate
    3. Todos os comandos e interações com a rede são executadas com a raíz em /hotfilm_NN

    O identificador "SERIE" é carregado desde os primeiros arquivos e comandos até o final, escolha-o estratégicamente para uma boa organização.
    Nos exemplos a seguir o identificador de série escolhido é "xyz"


Train:
 - treinar uma rede - 
    Para treinar um modelo, precisa-se de:
    -   Um conjunto de dados de tensão por tempo a 2000Hz do sensor hotfilm;
    -   Um conjunto de dados de velocidade por tempo a 20Hz do sensor sônico.  

    1. Preparação dos dados para treino: após a coleta dos dados em .csv, crie uma pasta única no formato dado_coletado_xxx dentro do diretório:
        dados/dados_cru/dados_cru_treino
        
    2. Depois de criada, a pasta deve conter dois arquivos: hotfilm_xxx.csv e sonic_xxx da seguinte forma:
        dados/dados_cru/dados_cru_train/dado_coletado_xxx/hotfilm_xxx.csv
        dados/dados_cru/dados_cru_train/dado_coletado_xxx/sonic_xxx.csv
        
    -> Exemplos:
        dado_coletado_xxx
        └──> hotfilm_xxx.csv
        └──> sonic_xxx.csv

        dado_coletado_leitura1
        └──> hotfilm_leitura1.csv
        └──> sonic_leitura1.csv
        
        obs: os arquivos dever ter o mesmo identificador de série da pasta:

    3. Com os dados dentro da pasta, cria-se o dataframe final que será usado para o treino, para isso, execute:
        $ python3 csv_maker.py train {serie que remete à pasta dentro de dados_cru_train} 

        -> Exemplo:
            $  python3 csv_maker.py train xxx
    
    4. Com o dataset de treinamento pronto e dentro da pasta:
        dados/treino/resultados_train/

       Pode-se começar o treinamento, com o seguinte comando' 
            $ python3 train_mlp.py train {serie} 

        -> Exemplo:
            $ python3 train_mlp.py xxx
   
    5. Resultados:
        Os meta dados serão salvos na pasta:
            dados/treino/resultados_train/
            Neste diretório acima será inserida uma planilha com as informações do treinamento e o nome do modelo respectivo a esse treinamento
            
        O modelo será salvo na pasta `modelos/` como:
            modelos/model_mlp_xxx.pth

    Observações de treinamento:
        Dentro do arquivo train_mlp.py há hiperparâmetros a serem alterados:

            EPOCHS          ->   determina a quantidade de vezes que o dataset passará pela rede de treinamento (1000 - padráo)
            EXPORT_DATA     ->   Exporta arquivos .csv (metadados) para analizar o resultado da rede
            GRAPHS          ->   Mostrar os gráficos ou não
            SAVE            ->   Salvar o modelo ou não
            GPU             ->   0 para uso da CPU (RECOMENDADO) | 1 para treino em GPU (código não otimizado para GPU não otimizado)      
            LOCAL           ->   0 para rodar em ambiente sem interface (sem mostrar os gráficos) | 1 para TREINO em SO com interface



Run: 
 - rodar dados em um modelo - 
    -> Para isso, precisa-se de:
    - Um modelo já treinado que esteja dentro de `modelos/`;
    - De um dataset de dados do hotfilm em tensão
    
    1. Após a coleta dos dados em .csv, crie uma pasta única no formato dado_coletado_xyz dentro do diretório:
        dados/dados_cru/dados_cru_run
        
    2. Depois de criada, a pasta deve conter o dataset hotfilm_xyz.csv da seguinte forma:
        dados/dados_cru/dados_cru_run/dado_coletado_xyz/hotfilm_xyz.csv
        
        Exemplos:
        dado_coletado_xyz
        └──> hotfilm_xyz.csv

        dado_coletado_leitura1
        └──> hotfilm_leitura1.csv
        
        dado_coletado_ensaio23
        └──> hotfilm_ensaio23.csv
        
        obs: o arquivo dever ter o mesmo identificador de série da pasta:


    3. execute, o seguinte comando para preparar os dados com conhecimento do identificador:
        $ python3 csv_maker.py run {serie} 
        
    -> Exemplo:
        $ python3 csv_maker.py run xyz

        Será salvo um arquivo único `run_xyz.csv` dentro do diretório
          dados/run
    
    4. Após essa preparação dos dados, execute o seguinte comando para processar os dados dentro da rede neural:

        $ python3 run_mlp.py {serie} {nome do modelo salvo}.pth

    -> Exemplo:
        $ python3 run_mlp.py xyz model_XXX.pth 

        Obs: Não esqueça de colocar o nome do modelo idêntico ao encontrado dentro da pasta `modelos/` junto de sua extensão .pth
    O resultado da execução será salvo dentro de uma pasta (velocity_xyz) com o mesmo identificador de série em: 
        dados/run/resultados_run

    Observações:
        O modelo deve estar dentro da pasta modelos ou abaixo (há de se especificar no argumento o subdiretório)
        Os dados de entrada têm de estar em .csv do seguinte formato:   | time, voltage_x, voltage_y, voltage_z |
        Os dados salvos serão encontrados em dados/gerados/ em uma pasta específica desse processamento com o identificador de série
